-*- mode: markup; -*-

* Code Challenge: Markup

* The task

The challenge, as accepted it, was to provide:

  # \i{The source code to a parser that, given the contents of a file in
    whatever form is natural for your language of choice—perhaps as an
    open stream or a string—returns a data structure representing the
    document tree as described in the [Markup specification] if the
    file is syntactically correct.}

    You find the code to what I would conisder a reasonable parser for
    Markup provided in src/lib.  Specifically, the Perl modules 
    \code{Markup::Tokenizer} and \code{Markup::Parser}.

  # \i{English language documentation for the data structure returned by
    the parser sufficient to allow a programmer familiar with your
    implementation language to write a back-end that generates some
    kind of output from the results returned by the parser.}

    Descriptions of the data structures returned by Markup::Parser may 
    be found in the pod\note{pod or 'Plain Old Documentation' is a standard 
    form of in line documentation used throughout Perl.  It can be viewed 
    using he \code{perldoc} utility like so:

       % perldoc Module::Parser
       % perldoc Module::Tree

    in location where perldoc can find the module in question.} documentation.
    A more detailed description will be provided towards the end of this 
    document. 

  # \i{The source code to a sample back-end that generates well-formed
    XML according to the “Trivial XML backend” section of the
    spec.\note{We don’t use XML because we have any great love for it
    but because it is a reasonable lowest-common-denominator format.}}

    A back-end meeting that above criteria can be found in the Perl
    module \code{Markup::Backend::XML}.  The back-end as an example:
    
       use Markup::Parser;
       use Markup::Tokenizer;
       use Markup::Backend::XML;
       
       my $tokenizer=Markup::Tokenizer->new(links => $links);
       my $parser=Markup::Parser->new(tokenizer => $tokenizer);
       my $backend=Markup::Backend::XML->new();

       # code to retrieve $source

       my $tree=$parser->parse($source);
       
       my $string=$backend->string($tree);
  
  # \i{The source code to a driver program that, given the name of a
    file, parses the file and then generates a corresponding XML file.}

    The file markup.pl in src should fulfill this particular requirement.
    
      - In a pipe:
         
	   % cat test | markup.pl | less

      - To stdout:
      
           % markup.pl test | less

      - To a file
      
           % markup.pl test -o test.xml

    You may also pass it the argument \code{--no-links} to turn off link 
    processing as required by the spec.

  # \i{Any libraries you use beyond those that are normally part of an
    installation of your chosen programming language.}

    Everything used is core Perl according to \code{Module::CoreList}.

  # \i{Any build instructions or scripts are needed to build the driver
    program or instructions how to run it if it requires no separate
    building.}

    Since this is Perl, there really aren't any build instructions.  The 
    shebang \node{For the users of that other operating system out there, 
    shebang it the \code{#!/usr/bin/perl} at the top of the script.  It 
    tells the system what program to use as an interpreter for the file.}
    assumes that perl is in /usr/bin.  Test cases can be run by calling 
    \code{prove} in the root directory of the project.  It should be able
    to locate the test files located in the t directory.

  # \i{Optionally, any notes about your experience implementing this
    code: how you came up with your design, blind alleys you went up,
    or surprising problems you ran into. Or anything else you want to
    share.}

    The commit log for this repository contains a good deal of these. I will
    definitely be fleshing things about a bit more here as well.


* Architectural Structure

The processor is broken down into four components, two of which contain the AST 
generation code, \code{Markup::Tokenizer} and \code{Markup::Parser}, one being the 
output back-end, \code{Markup::Backend::XML}, and the last being the \code{markup.pl}
driver script.  With the exception of \code{markup.pl}, each of these represents a
pass through a representation of the source data.  The entirety of the source data 
is loaded into a scalar variable and parsed as a whole to simplifying the parsing 
process.

** Markup::Tokenizer

The tokenizer is really a lexer in the spirit of lex.  It uses an array of prioritized 
regular expressions to match individual tokens within a string of text.  Once a token 
is matched, the matched text is removed from the beginning of the string and a new 
token search is started. If no token can be found at the start of the string, the 
tokenizer attempts to find the earliest match for any token that it can match.  
Anything between the current start of the string and that token is considered a raw 
text token.

Potential tokens are compared to a list of simple "must follow" rules to determine if 
a given token is legal in the current location.  If a rule is found for the given token,
it is compared to the previously matched token.  Tokens which are found to not follow
a token listed in their rule are either deleted, as in the case of an emacs mode line,
or converted into a text token.  When completed, \code{tokenize} will return an array 
or arrays containing a token symbol followed by the text matched to produce that symbol.

** Markup::Parser

